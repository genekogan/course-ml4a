{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "n_train, height, width = X_train.shape\n",
    "n_test, _, _ = X_test.shape\n",
    "\n",
    "n_train, n_test, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "samples = np.concatenate([np.concatenate([X_train[i].reshape(28,28) for i in [int(random.random() * len(X_train)) for i in range(16)]], axis=1) for i in range(4)], axis=0)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(samples, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# we have to preprocess the data into the right shape\n",
    "X_train = X_train.reshape(n_train, height, width, 1).astype('float32')\n",
    "X_test = X_test.reshape(n_test, height, width, 1).astype('float32')\n",
    "\n",
    "# normalize from [0, 255] to [0, 1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# numbers 0-9, so ten classes\n",
    "n_classes = 10\n",
    "\n",
    "# convert integer labels into one-hot vectors\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "# i.e. we will use a n_conv x n_conv filter\n",
    "n_conv = 3\n",
    "\n",
    "# pooling window size\n",
    "# i.e. we will use a n_pool x n_pool pooling window\n",
    "n_pool = 2\n",
    "\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, \n",
    "        kernel_size=(n_conv, n_conv),\n",
    "        # we have a 28x28 single channel (grayscale) image\n",
    "        # so the input shape should be (28, 28, 1)\n",
    "        input_shape=(height, width, 1)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# then we apply pooling to summarize the features\n",
    "# extracted thus far\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten the data for the 1D layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense(n_outputs)\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# the softmax output layer gives us a probablity for each class\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many examples to look at during each update step\n",
    "batch_size = 128\n",
    "\n",
    "# how many times to run through the full set of examples\n",
    "n_epochs = 10\n",
    "\n",
    "# the training may be slow depending on your computer\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how'd we do?\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = X_test[0].reshape(1,28,28,1)\n",
    "y_prob = model.predict(x_sample)[0]\n",
    "y_pred = y_prob.argmax()\n",
    "y_actual = y_test[0].argmax()\n",
    "\n",
    "print(\"probabilities: \", y_prob)\n",
    "print(\"predicted = %d, actual = %d\" % (y_pred, y_actual))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
